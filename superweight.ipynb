{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c4b44fb2c70475a976397b4d7e231c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b203048fd9bc4969b8a1980c1b4395a5",
              "IPY_MODEL_08884bd632d24699bed46841d7f3b0fd",
              "IPY_MODEL_44e831e7be8747a59ede4614e1d77d4d"
            ],
            "layout": "IPY_MODEL_6a4a5d1f9f5044179809ce61f05a5340"
          }
        },
        "b203048fd9bc4969b8a1980c1b4395a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9fdd3b27c0e45eeb1f0e72f50d06305",
            "placeholder": "​",
            "style": "IPY_MODEL_89e547dde93e4384b4624a995c227cd9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "08884bd632d24699bed46841d7f3b0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca64cd3e0d44c3faf45eab360aa5234",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79059a4e54b64846ab1e1145ba4f91d1",
            "value": 2
          }
        },
        "44e831e7be8747a59ede4614e1d77d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27a50824c3434511840face78380bcc1",
            "placeholder": "​",
            "style": "IPY_MODEL_8ade906671a1426f97c5915adcca8120",
            "value": " 2/2 [00:04&lt;00:00,  2.31s/it]"
          }
        },
        "6a4a5d1f9f5044179809ce61f05a5340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9fdd3b27c0e45eeb1f0e72f50d06305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89e547dde93e4384b4624a995c227cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eca64cd3e0d44c3faf45eab360aa5234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79059a4e54b64846ab1e1145ba4f91d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27a50824c3434511840face78380bcc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ade906671a1426f97c5915adcca8120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVFpsstXArgC",
        "outputId": "0a30548c-15ca-42bf-b5c7-fb73693de2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dMDdEVfOBJFk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SuperWeightFinder:\n",
        "    def __init__(self, model_name: str, device: str = \"cuda\"):\n",
        "        \"\"\"\n",
        "        Initialize the finder with a specified model\n",
        "\n",
        "        Args:\n",
        "            model_name: Name or path of the model\n",
        "            device: Device to load the model on (\"cuda\", \"cpu\", or specific CUDA device like \"cuda:0\")\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            device_map={\"\": torch.device(device)},\n",
        "            torch_dtype=torch.float16 if \"cuda\" in device else torch.float32\n",
        "        )\n",
        "        self.model.eval()\n",
        "\n",
        "    def register_hooks(self):\n",
        "        \"\"\"Register forward hooks to capture activations\"\"\"\n",
        "        self.down_proj_inputs = {}\n",
        "        self.down_proj_outputs = {}\n",
        "\n",
        "        def hook_fn(layer_idx, is_input):\n",
        "            def hook(module, input_tensors, output_tensors):\n",
        "                if is_input:\n",
        "                    self.down_proj_inputs[layer_idx] = input_tensors[0].detach()\n",
        "                else:\n",
        "                    self.down_proj_outputs[layer_idx] = output_tensors.detach()\n",
        "            return hook\n",
        "\n",
        "        for idx, layer in enumerate(self.model.model.layers):\n",
        "            layer.mlp.down_proj.register_forward_hook(hook_fn(idx, True))\n",
        "            layer.mlp.down_proj.register_forward_hook(hook_fn(idx, False))\n",
        "\n",
        "#    def verify_super_weight(self, candidate: Dict, test_prompt: str = \"My favorite condiment is\") -> Dict:\n",
        "    def verify_super_weight(self, candidate: Dict, test_prompt: str = \"Q: トマトは何色ですか？\\nA: \") -> Dict:\n",
        "        \"\"\"Super weight候補の重要性を検証\"\"\"\n",
        "        layer = self.model.model.layers[candidate['layer']]\n",
        "        original_weight = float(layer.mlp.down_proj.weight[candidate['row'], candidate['col']])\n",
        "\n",
        "        inputs = self.tokenizer(test_prompt, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            original_output = self.model.generate(\n",
        "                inputs.input_ids,\n",
        "                max_length=50,\n",
        "                num_return_sequences=1,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "        original_text = self.tokenizer.decode(original_output[0], skip_special_tokens=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            layer.mlp.down_proj.weight[candidate['row'], candidate['col']] = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            modified_output = self.model.generate(\n",
        "                inputs.input_ids,\n",
        "                max_length=50,\n",
        "                num_return_sequences=1,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "        modified_text = self.tokenizer.decode(modified_output[0], skip_special_tokens=True)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            layer.mlp.down_proj.weight[candidate['row'], candidate['col']] = original_weight\n",
        "\n",
        "        return {\n",
        "            'candidate': candidate,\n",
        "            'original_output': original_text,\n",
        "            'modified_output': modified_text,\n",
        "            'impact': original_text != modified_text\n",
        "        }\n",
        "    def find_super_weights(self, sample_text: str, magnitude_threshold: float = 50.0) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        論文の手法に基づいてSuper weightを特定する（改良版）\n",
        "\n",
        "        Args:\n",
        "            sample_text: 分析に使用するサンプルテキスト\n",
        "            magnitude_threshold: 活性化値の大きさの閾値\n",
        "        \"\"\"\n",
        "        self.register_hooks()\n",
        "        inputs = self.tokenizer(sample_text, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.model(**inputs)\n",
        "\n",
        "        # レイヤーごとの最大活性化値を記録\n",
        "        layer_activations = {}\n",
        "        for layer_idx in self.down_proj_inputs.keys():\n",
        "            input_tensor = self.down_proj_inputs[layer_idx]  # [batch, seq_len, hidden_dim]\n",
        "            output_tensor = self.down_proj_outputs[layer_idx]  # [batch, seq_len, output_dim]\n",
        "\n",
        "            # 各位置での最大活性化値を計算\n",
        "            input_max = torch.amax(torch.abs(input_tensor), dim=(0, 1))  # [hidden_dim]\n",
        "            output_max = torch.amax(torch.abs(output_tensor), dim=(0, 1))  # [output_dim]\n",
        "\n",
        "            layer_activations[layer_idx] = {\n",
        "                'input_max': input_max,\n",
        "                'output_max': output_max,\n",
        "                'input_tensor': input_tensor,\n",
        "                'output_tensor': output_tensor\n",
        "            }\n",
        "\n",
        "        # Super weightの候補を見つける\n",
        "        super_weight_candidates = []\n",
        "        for layer_idx, activations in layer_activations.items():\n",
        "            layer = self.model.model.layers[layer_idx]\n",
        "            weight_matrix = layer.mlp.down_proj.weight  # [output_dim, hidden_dim]\n",
        "\n",
        "            # 入力の大きな活性化値を持つチャネルを特定\n",
        "            input_peaks = torch.where(activations['input_max'] > magnitude_threshold)[0]\n",
        "\n",
        "            # 出力の大きな活性化値を持つチャネルを特定\n",
        "            output_peaks = torch.where(activations['output_max'] > magnitude_threshold)[0]\n",
        "\n",
        "            if len(input_peaks) > 0 and len(output_peaks) > 0:\n",
        "                for out_idx in output_peaks:\n",
        "                    for in_idx in input_peaks:\n",
        "                        weight_value = float(weight_matrix[out_idx, in_idx])\n",
        "\n",
        "                        # Super weightの候補を記録\n",
        "                        candidate = {\n",
        "                            'layer': layer_idx,\n",
        "                            'row': int(out_idx),\n",
        "                            'col': int(in_idx),\n",
        "                            'weight_value': weight_value,\n",
        "                            'input_magnitude': float(activations['input_max'][in_idx]),\n",
        "                            'output_magnitude': float(activations['output_max'][out_idx])\n",
        "                        }\n",
        "\n",
        "                        # 後続のレイヤーでのsuper activationの持続を確認\n",
        "                        subsequent_magnitudes = []\n",
        "                        for subsequent_layer in range(layer_idx + 1, len(self.model.model.layers)):\n",
        "                            if subsequent_layer in layer_activations:\n",
        "                                out_magnitude = float(layer_activations[subsequent_layer]['output_max'][out_idx])\n",
        "                                subsequent_magnitudes.append(out_magnitude)\n",
        "\n",
        "                        candidate['subsequent_magnitudes'] = subsequent_magnitudes\n",
        "                        candidate['persistence_score'] = np.mean(subsequent_magnitudes) if subsequent_magnitudes else 0\n",
        "\n",
        "                        super_weight_candidates.append(candidate)\n",
        "\n",
        "        # 候補をスコアでソート\n",
        "        # 1. 活性化値の大きさ\n",
        "        # 2. 後続レイヤーでの持続性\n",
        "        super_weight_candidates.sort(\n",
        "            key=lambda x: (x['input_magnitude'] * x['output_magnitude'] * x['persistence_score']),\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        return super_weight_candidates\n",
        "\n",
        "    def calculate_perplexity(self, text: str, candidate: Dict = None) -> float:\n",
        "        \"\"\"\n",
        "        テキストのperplexityを計算する。candidateが指定された場合は、そのSuper weightを0にした状態で計算\n",
        "\n",
        "        Args:\n",
        "            text: 評価するテキスト\n",
        "            candidate: Super weightの候補（Noneの場合は元のモデルでperplexityを計算）\n",
        "\n",
        "        Returns:\n",
        "            float: 計算されたperplexity\n",
        "        \"\"\"\n",
        "        # 入力をトークナイズ\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        original_weight = None\n",
        "        if candidate is not None:\n",
        "            # Super weightの値を一時的に保存して0に設定\n",
        "            layer = self.model.model.layers[candidate['layer']]\n",
        "            original_weight = float(layer.mlp.down_proj.weight[candidate['row'], candidate['col']])\n",
        "            with torch.no_grad():\n",
        "                layer.mlp.down_proj.weight[candidate['row'], candidate['col']] = 0.0\n",
        "\n",
        "        # perplexityの計算\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # シフトしたターゲットを作成\n",
        "            target_ids = inputs.input_ids[..., 1:]\n",
        "            shift_logits = logits[..., :-1, :]\n",
        "\n",
        "            # loss計算\n",
        "            loss_fct = torch.nn.CrossEntropyLoss()\n",
        "            shift_logits = shift_logits.reshape(-1, shift_logits.size(-1))\n",
        "            target_ids = target_ids.reshape(-1)\n",
        "            loss = loss_fct(shift_logits, target_ids)\n",
        "\n",
        "            perplexity = torch.exp(loss).item()\n",
        "\n",
        "        # Super weightを元に戻す\n",
        "        if original_weight is not None:\n",
        "            with torch.no_grad():\n",
        "                layer.mlp.down_proj.weight[candidate['row'], candidate['col']] = original_weight\n",
        "\n",
        "        return perplexity\n",
        "\n",
        "    def evaluate_candidates(self, candidates: List[Dict], eval_text: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        候補のSuper weightを評価する\n",
        "\n",
        "        Args:\n",
        "            candidates: Super weightの候補リスト\n",
        "            eval_text: 評価に使用するテキスト\n",
        "\n",
        "        Returns:\n",
        "            List[Dict]: 評価結果を含む候補リスト\n",
        "        \"\"\"\n",
        "        # 元のモデルのperplexityを計算\n",
        "        base_perplexity = self.calculate_perplexity(eval_text)\n",
        "        print(f\"Base perplexity: {base_perplexity:.2f}\")\n",
        "\n",
        "        evaluated_candidates = []\n",
        "        for i, candidate in enumerate(candidates):\n",
        "            # Super weightを0にした状態でのperplexityを計算\n",
        "            modified_perplexity = self.calculate_perplexity(eval_text, candidate)\n",
        "\n",
        "            # perplexityの変化率を計算\n",
        "            perplexity_change = ((modified_perplexity - base_perplexity) / base_perplexity) * 100\n",
        "\n",
        "            # 評価結果を追加\n",
        "            candidate_with_eval = {\n",
        "                **candidate,\n",
        "                'base_perplexity': base_perplexity,\n",
        "                'modified_perplexity': modified_perplexity,\n",
        "                'perplexity_change_percent': perplexity_change\n",
        "            }\n",
        "            evaluated_candidates.append(candidate_with_eval)\n",
        "\n",
        "            print(f\"Candidate {i+1}/{len(candidates)}:\")\n",
        "            print(f\"Layer: {candidate['layer']}, Position: ({candidate['row']}, {candidate['col']})\")\n",
        "            print(f\"Modified perplexity: {modified_perplexity:.2f}\")\n",
        "            print(f\"Perplexity change: {perplexity_change:+.2f}%\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        # perplexityの変化が大きい順にソート\n",
        "        evaluated_candidates.sort(key=lambda x: abs(x['perplexity_change_percent']), reverse=True)\n",
        "\n",
        "        return evaluated_candidates"
      ],
      "metadata": {
        "id": "-y9Iy6oJBOiT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テスターのインスタンスを作成\n",
        "finder = SuperWeightFinder(\"llm-jp/llm-jp-3-3.7b\",  device=\"cuda\")\n",
        "#finder = SuperWeightFinder(\"mistralai/Mistral-7B-v0.1\",  device=\"cuda\")\n",
        "#finder = SuperWeightFinder(\"meta-llama/Llama-2-7b-hf\",  device=\"cuda\")\n",
        "#finder = SuperWeightFinder(\"meta-llama/Llama-3.2-3B\",  device=\"cuda\")\n",
        "#finder = SuperWeightFinder(\"meta-llama/Llama-3.1-8B\",  device=\"cuda\")\n",
        "#finder = SuperWeightFinder(\"sbintuitions/sarashina2-7b\",  device=\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2c4b44fb2c70475a976397b4d7e231c1",
            "b203048fd9bc4969b8a1980c1b4395a5",
            "08884bd632d24699bed46841d7f3b0fd",
            "44e831e7be8747a59ede4614e1d77d4d",
            "6a4a5d1f9f5044179809ce61f05a5340",
            "f9fdd3b27c0e45eeb1f0e72f50d06305",
            "89e547dde93e4384b4624a995c227cd9",
            "eca64cd3e0d44c3faf45eab360aa5234",
            "79059a4e54b64846ab1e1145ba4f91d1",
            "27a50824c3434511840face78380bcc1",
            "8ade906671a1426f97c5915adcca8120"
          ]
        },
        "id": "EJ-d7TOIBQdL",
        "outputId": "a6319149-7d2c-402a-fb74-0e06816cd7e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c4b44fb2c70475a976397b4d7e231c1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# テストテキストを使ってSuper weightを探す\n",
        "test_text = \"富士山は山梨県と静岡県に跨る活火山である。標高3776.12 m、日本最高峰の独立峰で、その優美な風貌は日本国外でも日本の象徴として広く知られている。\"\n",
        "#test_text = \"The highest mountain in Japan is\"\n",
        "candidates = finder.find_super_weights(test_text)"
      ],
      "metadata": {
        "id": "Xp1L7MvABjyL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価用のテキスト\n",
        "eval_text = \"\"\"ドメイン特化のLLMが一つのトレンドで、医療や金融では盛んに開発が行われていることもあり、モデルやデータセット、ベンチマークなどは充実しています。\"\"\"\n",
        "\n",
        "# 候補を評価\n",
        "evaluated_candidates = finder.evaluate_candidates(candidates, eval_text)\n",
        "\n",
        "# 結果を表示\n",
        "print(\"\\nTop 3 most influential Super weights:\")\n",
        "for i, candidate in enumerate(evaluated_candidates[:3]):\n",
        "    print(f\"\\nCandidate {i+1}:\")\n",
        "    print(f\"Layer: {candidate['layer']}\")\n",
        "    print(f\"Position: ({candidate['row']}, {candidate['col']})\")\n",
        "    print(f\"Weight value: {candidate['weight_value']:.4f}\")\n",
        "    print(f\"Perplexity impact: {candidate['perplexity_change_percent']:+.2f}%\")\n",
        "    print(f\"Base perplexity: {candidate['base_perplexity']:.2f}\")\n",
        "    print(f\"Modified perplexity: {candidate['modified_perplexity']:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCc5KTMTCT7h",
        "outputId": "03c5243d-6959-4125-ffd2-42d8d5a2dd10"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base perplexity: 63.09\n",
            "Candidate 1/265:\n",
            "Layer: 26, Position: (1161, 2736)\n",
            "Modified perplexity: 68.19\n",
            "Perplexity change: +8.07%\n",
            "--------------------------------------------------\n",
            "Candidate 2/265:\n",
            "Layer: 26, Position: (1264, 2736)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 3/265:\n",
            "Layer: 7, Position: (1161, 546)\n",
            "Modified perplexity: 75.50\n",
            "Perplexity change: +19.66%\n",
            "--------------------------------------------------\n",
            "Candidate 4/265:\n",
            "Layer: 7, Position: (1264, 546)\n",
            "Modified perplexity: 72.06\n",
            "Perplexity change: +14.21%\n",
            "--------------------------------------------------\n",
            "Candidate 5/265:\n",
            "Layer: 26, Position: (1161, 3464)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 6/265:\n",
            "Layer: 7, Position: (1161, 5535)\n",
            "Modified perplexity: 59.50\n",
            "Perplexity change: -5.70%\n",
            "--------------------------------------------------\n",
            "Candidate 7/265:\n",
            "Layer: 26, Position: (1264, 3464)\n",
            "Modified perplexity: 61.88\n",
            "Perplexity change: -1.93%\n",
            "--------------------------------------------------\n",
            "Candidate 8/265:\n",
            "Layer: 26, Position: (963, 2736)\n",
            "Modified perplexity: 60.44\n",
            "Perplexity change: -4.21%\n",
            "--------------------------------------------------\n",
            "Candidate 9/265:\n",
            "Layer: 7, Position: (1264, 5535)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 10/265:\n",
            "Layer: 7, Position: (963, 546)\n",
            "Modified perplexity: 59.50\n",
            "Perplexity change: -5.70%\n",
            "--------------------------------------------------\n",
            "Candidate 11/265:\n",
            "Layer: 26, Position: (2938, 2736)\n",
            "Modified perplexity: 62.59\n",
            "Perplexity change: -0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 12/265:\n",
            "Layer: 26, Position: (347, 2736)\n",
            "Modified perplexity: 64.56\n",
            "Perplexity change: +2.33%\n",
            "--------------------------------------------------\n",
            "Candidate 13/265:\n",
            "Layer: 26, Position: (257, 2736)\n",
            "Modified perplexity: 62.34\n",
            "Perplexity change: -1.19%\n",
            "--------------------------------------------------\n",
            "Candidate 14/265:\n",
            "Layer: 7, Position: (2938, 546)\n",
            "Modified perplexity: 59.97\n",
            "Perplexity change: -4.95%\n",
            "--------------------------------------------------\n",
            "Candidate 15/265:\n",
            "Layer: 26, Position: (2139, 2736)\n",
            "Modified perplexity: 57.22\n",
            "Perplexity change: -9.31%\n",
            "--------------------------------------------------\n",
            "Candidate 16/265:\n",
            "Layer: 7, Position: (963, 5535)\n",
            "Modified perplexity: 61.38\n",
            "Perplexity change: -2.72%\n",
            "--------------------------------------------------\n",
            "Candidate 17/265:\n",
            "Layer: 26, Position: (963, 3464)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 18/265:\n",
            "Layer: 7, Position: (257, 546)\n",
            "Modified perplexity: 66.88\n",
            "Perplexity change: +5.99%\n",
            "--------------------------------------------------\n",
            "Candidate 19/265:\n",
            "Layer: 7, Position: (2938, 5535)\n",
            "Modified perplexity: 61.88\n",
            "Perplexity change: -1.93%\n",
            "--------------------------------------------------\n",
            "Candidate 20/265:\n",
            "Layer: 7, Position: (2139, 546)\n",
            "Modified perplexity: 75.19\n",
            "Perplexity change: +19.17%\n",
            "--------------------------------------------------\n",
            "Candidate 21/265:\n",
            "Layer: 26, Position: (2938, 3464)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 22/265:\n",
            "Layer: 26, Position: (347, 3464)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 23/265:\n",
            "Layer: 26, Position: (257, 3464)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 24/265:\n",
            "Layer: 1, Position: (2938, 7633)\n",
            "Modified perplexity: 21344.00\n",
            "Perplexity change: +33729.02%\n",
            "--------------------------------------------------\n",
            "Candidate 25/265:\n",
            "Layer: 7, Position: (257, 5535)\n",
            "Modified perplexity: 63.59\n",
            "Perplexity change: +0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 26/265:\n",
            "Layer: 26, Position: (2139, 3464)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 27/265:\n",
            "Layer: 7, Position: (2139, 5535)\n",
            "Modified perplexity: 64.81\n",
            "Perplexity change: +2.72%\n",
            "--------------------------------------------------\n",
            "Candidate 28/265:\n",
            "Layer: 27, Position: (32, 355)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 29/265:\n",
            "Layer: 27, Position: (32, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 30/265:\n",
            "Layer: 27, Position: (32, 1328)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 31/265:\n",
            "Layer: 27, Position: (32, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 32/265:\n",
            "Layer: 27, Position: (32, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 33/265:\n",
            "Layer: 27, Position: (32, 2449)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 34/265:\n",
            "Layer: 27, Position: (32, 2670)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 35/265:\n",
            "Layer: 27, Position: (32, 2991)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 36/265:\n",
            "Layer: 27, Position: (32, 3290)\n",
            "Modified perplexity: 63.59\n",
            "Perplexity change: +0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 37/265:\n",
            "Layer: 27, Position: (32, 3550)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 38/265:\n",
            "Layer: 27, Position: (32, 4577)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 39/265:\n",
            "Layer: 27, Position: (32, 5255)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 40/265:\n",
            "Layer: 27, Position: (32, 5365)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 41/265:\n",
            "Layer: 27, Position: (32, 5965)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 42/265:\n",
            "Layer: 27, Position: (32, 6023)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 43/265:\n",
            "Layer: 27, Position: (32, 6131)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 44/265:\n",
            "Layer: 27, Position: (32, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 45/265:\n",
            "Layer: 27, Position: (257, 355)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 46/265:\n",
            "Layer: 27, Position: (257, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 47/265:\n",
            "Layer: 27, Position: (257, 1328)\n",
            "Modified perplexity: 63.84\n",
            "Perplexity change: +1.19%\n",
            "--------------------------------------------------\n",
            "Candidate 48/265:\n",
            "Layer: 27, Position: (257, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 49/265:\n",
            "Layer: 27, Position: (257, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 50/265:\n",
            "Layer: 27, Position: (257, 2449)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 51/265:\n",
            "Layer: 27, Position: (257, 2670)\n",
            "Modified perplexity: 62.59\n",
            "Perplexity change: -0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 52/265:\n",
            "Layer: 27, Position: (257, 2991)\n",
            "Modified perplexity: 62.59\n",
            "Perplexity change: -0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 53/265:\n",
            "Layer: 27, Position: (257, 3290)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 54/265:\n",
            "Layer: 27, Position: (257, 3550)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 55/265:\n",
            "Layer: 27, Position: (257, 4577)\n",
            "Modified perplexity: 63.59\n",
            "Perplexity change: +0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 56/265:\n",
            "Layer: 27, Position: (257, 5255)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 57/265:\n",
            "Layer: 27, Position: (257, 5365)\n",
            "Modified perplexity: 62.59\n",
            "Perplexity change: -0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 58/265:\n",
            "Layer: 27, Position: (257, 5965)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 59/265:\n",
            "Layer: 27, Position: (257, 6023)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 60/265:\n",
            "Layer: 27, Position: (257, 6131)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 61/265:\n",
            "Layer: 27, Position: (257, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 62/265:\n",
            "Layer: 27, Position: (347, 355)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 63/265:\n",
            "Layer: 27, Position: (347, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 64/265:\n",
            "Layer: 27, Position: (347, 1328)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 65/265:\n",
            "Layer: 27, Position: (347, 2143)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 66/265:\n",
            "Layer: 27, Position: (347, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 67/265:\n",
            "Layer: 27, Position: (347, 2449)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 68/265:\n",
            "Layer: 27, Position: (347, 2670)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 69/265:\n",
            "Layer: 27, Position: (347, 2991)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 70/265:\n",
            "Layer: 27, Position: (347, 3290)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 71/265:\n",
            "Layer: 27, Position: (347, 3550)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 72/265:\n",
            "Layer: 27, Position: (347, 4577)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 73/265:\n",
            "Layer: 27, Position: (347, 5255)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 74/265:\n",
            "Layer: 27, Position: (347, 5365)\n",
            "Modified perplexity: 63.59\n",
            "Perplexity change: +0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 75/265:\n",
            "Layer: 27, Position: (347, 5965)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 76/265:\n",
            "Layer: 27, Position: (347, 6023)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 77/265:\n",
            "Layer: 27, Position: (347, 6131)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 78/265:\n",
            "Layer: 27, Position: (347, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 79/265:\n",
            "Layer: 27, Position: (639, 355)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 80/265:\n",
            "Layer: 27, Position: (639, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 81/265:\n",
            "Layer: 27, Position: (639, 1328)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 82/265:\n",
            "Layer: 27, Position: (639, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 83/265:\n",
            "Layer: 27, Position: (639, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 84/265:\n",
            "Layer: 27, Position: (639, 2449)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 85/265:\n",
            "Layer: 27, Position: (639, 2670)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 86/265:\n",
            "Layer: 27, Position: (639, 2991)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 87/265:\n",
            "Layer: 27, Position: (639, 3290)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 88/265:\n",
            "Layer: 27, Position: (639, 3550)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 89/265:\n",
            "Layer: 27, Position: (639, 4577)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 90/265:\n",
            "Layer: 27, Position: (639, 5255)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 91/265:\n",
            "Layer: 27, Position: (639, 5365)\n",
            "Modified perplexity: 62.59\n",
            "Perplexity change: -0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 92/265:\n",
            "Layer: 27, Position: (639, 5965)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 93/265:\n",
            "Layer: 27, Position: (639, 6023)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 94/265:\n",
            "Layer: 27, Position: (639, 6131)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 95/265:\n",
            "Layer: 27, Position: (639, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 96/265:\n",
            "Layer: 27, Position: (963, 355)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 97/265:\n",
            "Layer: 27, Position: (963, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 98/265:\n",
            "Layer: 27, Position: (963, 1328)\n",
            "Modified perplexity: 62.59\n",
            "Perplexity change: -0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 99/265:\n",
            "Layer: 27, Position: (963, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 100/265:\n",
            "Layer: 27, Position: (963, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 101/265:\n",
            "Layer: 27, Position: (963, 2449)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 102/265:\n",
            "Layer: 27, Position: (963, 2670)\n",
            "Modified perplexity: 63.59\n",
            "Perplexity change: +0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 103/265:\n",
            "Layer: 27, Position: (963, 2991)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 104/265:\n",
            "Layer: 27, Position: (963, 3290)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 105/265:\n",
            "Layer: 27, Position: (963, 3550)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 106/265:\n",
            "Layer: 27, Position: (963, 4577)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 107/265:\n",
            "Layer: 27, Position: (963, 5255)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 108/265:\n",
            "Layer: 27, Position: (963, 5365)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 109/265:\n",
            "Layer: 27, Position: (963, 5965)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 110/265:\n",
            "Layer: 27, Position: (963, 6023)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 111/265:\n",
            "Layer: 27, Position: (963, 6131)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 112/265:\n",
            "Layer: 27, Position: (963, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 113/265:\n",
            "Layer: 27, Position: (1161, 355)\n",
            "Modified perplexity: 62.59\n",
            "Perplexity change: -0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 114/265:\n",
            "Layer: 27, Position: (1161, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 115/265:\n",
            "Layer: 27, Position: (1161, 1328)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 116/265:\n",
            "Layer: 27, Position: (1161, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 117/265:\n",
            "Layer: 27, Position: (1161, 2418)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 118/265:\n",
            "Layer: 27, Position: (1161, 2449)\n",
            "Modified perplexity: 61.88\n",
            "Perplexity change: -1.93%\n",
            "--------------------------------------------------\n",
            "Candidate 119/265:\n",
            "Layer: 27, Position: (1161, 2670)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 120/265:\n",
            "Layer: 27, Position: (1161, 2991)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 121/265:\n",
            "Layer: 27, Position: (1161, 3290)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 122/265:\n",
            "Layer: 27, Position: (1161, 3550)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 123/265:\n",
            "Layer: 27, Position: (1161, 4577)\n",
            "Modified perplexity: 60.91\n",
            "Perplexity change: -3.47%\n",
            "--------------------------------------------------\n",
            "Candidate 124/265:\n",
            "Layer: 27, Position: (1161, 5255)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 125/265:\n",
            "Layer: 27, Position: (1161, 5365)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 126/265:\n",
            "Layer: 27, Position: (1161, 5965)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 127/265:\n",
            "Layer: 27, Position: (1161, 6023)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 128/265:\n",
            "Layer: 27, Position: (1161, 6131)\n",
            "Modified perplexity: 61.16\n",
            "Perplexity change: -3.07%\n",
            "--------------------------------------------------\n",
            "Candidate 129/265:\n",
            "Layer: 27, Position: (1161, 6452)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 130/265:\n",
            "Layer: 27, Position: (1264, 355)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 131/265:\n",
            "Layer: 27, Position: (1264, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 132/265:\n",
            "Layer: 27, Position: (1264, 1328)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 133/265:\n",
            "Layer: 27, Position: (1264, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 134/265:\n",
            "Layer: 27, Position: (1264, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 135/265:\n",
            "Layer: 27, Position: (1264, 2449)\n",
            "Modified perplexity: 62.34\n",
            "Perplexity change: -1.19%\n",
            "--------------------------------------------------\n",
            "Candidate 136/265:\n",
            "Layer: 27, Position: (1264, 2670)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 137/265:\n",
            "Layer: 27, Position: (1264, 2991)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 138/265:\n",
            "Layer: 27, Position: (1264, 3290)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 139/265:\n",
            "Layer: 27, Position: (1264, 3550)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 140/265:\n",
            "Layer: 27, Position: (1264, 4577)\n",
            "Modified perplexity: 60.66\n",
            "Perplexity change: -3.86%\n",
            "--------------------------------------------------\n",
            "Candidate 141/265:\n",
            "Layer: 27, Position: (1264, 5255)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 142/265:\n",
            "Layer: 27, Position: (1264, 5365)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 143/265:\n",
            "Layer: 27, Position: (1264, 5965)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 144/265:\n",
            "Layer: 27, Position: (1264, 6023)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 145/265:\n",
            "Layer: 27, Position: (1264, 6131)\n",
            "Modified perplexity: 61.38\n",
            "Perplexity change: -2.72%\n",
            "--------------------------------------------------\n",
            "Candidate 146/265:\n",
            "Layer: 27, Position: (1264, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 147/265:\n",
            "Layer: 27, Position: (1278, 355)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 148/265:\n",
            "Layer: 27, Position: (1278, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 149/265:\n",
            "Layer: 27, Position: (1278, 1328)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 150/265:\n",
            "Layer: 27, Position: (1278, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 151/265:\n",
            "Layer: 27, Position: (1278, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 152/265:\n",
            "Layer: 27, Position: (1278, 2449)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 153/265:\n",
            "Layer: 27, Position: (1278, 2670)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 154/265:\n",
            "Layer: 27, Position: (1278, 2991)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 155/265:\n",
            "Layer: 27, Position: (1278, 3290)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 156/265:\n",
            "Layer: 27, Position: (1278, 3550)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 157/265:\n",
            "Layer: 27, Position: (1278, 4577)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 158/265:\n",
            "Layer: 27, Position: (1278, 5255)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 159/265:\n",
            "Layer: 27, Position: (1278, 5365)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 160/265:\n",
            "Layer: 27, Position: (1278, 5965)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 161/265:\n",
            "Layer: 27, Position: (1278, 6023)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 162/265:\n",
            "Layer: 27, Position: (1278, 6131)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 163/265:\n",
            "Layer: 27, Position: (1278, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 164/265:\n",
            "Layer: 27, Position: (1583, 355)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 165/265:\n",
            "Layer: 27, Position: (1583, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 166/265:\n",
            "Layer: 27, Position: (1583, 1328)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 167/265:\n",
            "Layer: 27, Position: (1583, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 168/265:\n",
            "Layer: 27, Position: (1583, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 169/265:\n",
            "Layer: 27, Position: (1583, 2449)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 170/265:\n",
            "Layer: 27, Position: (1583, 2670)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 171/265:\n",
            "Layer: 27, Position: (1583, 2991)\n",
            "Modified perplexity: 63.59\n",
            "Perplexity change: +0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 172/265:\n",
            "Layer: 27, Position: (1583, 3290)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 173/265:\n",
            "Layer: 27, Position: (1583, 3550)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 174/265:\n",
            "Layer: 27, Position: (1583, 4577)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 175/265:\n",
            "Layer: 27, Position: (1583, 5255)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 176/265:\n",
            "Layer: 27, Position: (1583, 5365)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 177/265:\n",
            "Layer: 27, Position: (1583, 5965)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 178/265:\n",
            "Layer: 27, Position: (1583, 6023)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 179/265:\n",
            "Layer: 27, Position: (1583, 6131)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 180/265:\n",
            "Layer: 27, Position: (1583, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 181/265:\n",
            "Layer: 27, Position: (1855, 355)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 182/265:\n",
            "Layer: 27, Position: (1855, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 183/265:\n",
            "Layer: 27, Position: (1855, 1328)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 184/265:\n",
            "Layer: 27, Position: (1855, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 185/265:\n",
            "Layer: 27, Position: (1855, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 186/265:\n",
            "Layer: 27, Position: (1855, 2449)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 187/265:\n",
            "Layer: 27, Position: (1855, 2670)\n",
            "Modified perplexity: 64.06\n",
            "Perplexity change: +1.54%\n",
            "--------------------------------------------------\n",
            "Candidate 188/265:\n",
            "Layer: 27, Position: (1855, 2991)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 189/265:\n",
            "Layer: 27, Position: (1855, 3290)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 190/265:\n",
            "Layer: 27, Position: (1855, 3550)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 191/265:\n",
            "Layer: 27, Position: (1855, 4577)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 192/265:\n",
            "Layer: 27, Position: (1855, 5255)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 193/265:\n",
            "Layer: 27, Position: (1855, 5365)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 194/265:\n",
            "Layer: 27, Position: (1855, 5965)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 195/265:\n",
            "Layer: 27, Position: (1855, 6023)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 196/265:\n",
            "Layer: 27, Position: (1855, 6131)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 197/265:\n",
            "Layer: 27, Position: (1855, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 198/265:\n",
            "Layer: 27, Position: (1965, 355)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 199/265:\n",
            "Layer: 27, Position: (1965, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 200/265:\n",
            "Layer: 27, Position: (1965, 1328)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 201/265:\n",
            "Layer: 27, Position: (1965, 2143)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 202/265:\n",
            "Layer: 27, Position: (1965, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 203/265:\n",
            "Layer: 27, Position: (1965, 2449)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 204/265:\n",
            "Layer: 27, Position: (1965, 2670)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 205/265:\n",
            "Layer: 27, Position: (1965, 2991)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 206/265:\n",
            "Layer: 27, Position: (1965, 3290)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 207/265:\n",
            "Layer: 27, Position: (1965, 3550)\n",
            "Modified perplexity: 63.59\n",
            "Perplexity change: +0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 208/265:\n",
            "Layer: 27, Position: (1965, 4577)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 209/265:\n",
            "Layer: 27, Position: (1965, 5255)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 210/265:\n",
            "Layer: 27, Position: (1965, 5365)\n",
            "Modified perplexity: 63.59\n",
            "Perplexity change: +0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 211/265:\n",
            "Layer: 27, Position: (1965, 5965)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 212/265:\n",
            "Layer: 27, Position: (1965, 6023)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 213/265:\n",
            "Layer: 27, Position: (1965, 6131)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 214/265:\n",
            "Layer: 27, Position: (1965, 6452)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 215/265:\n",
            "Layer: 27, Position: (2010, 355)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 216/265:\n",
            "Layer: 27, Position: (2010, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 217/265:\n",
            "Layer: 27, Position: (2010, 1328)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 218/265:\n",
            "Layer: 27, Position: (2010, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 219/265:\n",
            "Layer: 27, Position: (2010, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 220/265:\n",
            "Layer: 27, Position: (2010, 2449)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 221/265:\n",
            "Layer: 27, Position: (2010, 2670)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 222/265:\n",
            "Layer: 27, Position: (2010, 2991)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 223/265:\n",
            "Layer: 27, Position: (2010, 3290)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 224/265:\n",
            "Layer: 27, Position: (2010, 3550)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 225/265:\n",
            "Layer: 27, Position: (2010, 4577)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 226/265:\n",
            "Layer: 27, Position: (2010, 5255)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 227/265:\n",
            "Layer: 27, Position: (2010, 5365)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 228/265:\n",
            "Layer: 27, Position: (2010, 5965)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 229/265:\n",
            "Layer: 27, Position: (2010, 6023)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 230/265:\n",
            "Layer: 27, Position: (2010, 6131)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 231/265:\n",
            "Layer: 27, Position: (2010, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 232/265:\n",
            "Layer: 27, Position: (2139, 355)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 233/265:\n",
            "Layer: 27, Position: (2139, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 234/265:\n",
            "Layer: 27, Position: (2139, 1328)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 235/265:\n",
            "Layer: 27, Position: (2139, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 236/265:\n",
            "Layer: 27, Position: (2139, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 237/265:\n",
            "Layer: 27, Position: (2139, 2449)\n",
            "Modified perplexity: 62.59\n",
            "Perplexity change: -0.79%\n",
            "--------------------------------------------------\n",
            "Candidate 238/265:\n",
            "Layer: 27, Position: (2139, 2670)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 239/265:\n",
            "Layer: 27, Position: (2139, 2991)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 240/265:\n",
            "Layer: 27, Position: (2139, 3290)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 241/265:\n",
            "Layer: 27, Position: (2139, 3550)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 242/265:\n",
            "Layer: 27, Position: (2139, 4577)\n",
            "Modified perplexity: 61.62\n",
            "Perplexity change: -2.33%\n",
            "--------------------------------------------------\n",
            "Candidate 243/265:\n",
            "Layer: 27, Position: (2139, 5255)\n",
            "Modified perplexity: 63.34\n",
            "Perplexity change: +0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 244/265:\n",
            "Layer: 27, Position: (2139, 5365)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 245/265:\n",
            "Layer: 27, Position: (2139, 5965)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 246/265:\n",
            "Layer: 27, Position: (2139, 6023)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 247/265:\n",
            "Layer: 27, Position: (2139, 6131)\n",
            "Modified perplexity: 61.62\n",
            "Perplexity change: -2.33%\n",
            "--------------------------------------------------\n",
            "Candidate 248/265:\n",
            "Layer: 27, Position: (2139, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 249/265:\n",
            "Layer: 27, Position: (2938, 355)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 250/265:\n",
            "Layer: 27, Position: (2938, 392)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 251/265:\n",
            "Layer: 27, Position: (2938, 1328)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 252/265:\n",
            "Layer: 27, Position: (2938, 2143)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 253/265:\n",
            "Layer: 27, Position: (2938, 2418)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 254/265:\n",
            "Layer: 27, Position: (2938, 2449)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 255/265:\n",
            "Layer: 27, Position: (2938, 2670)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 256/265:\n",
            "Layer: 27, Position: (2938, 2991)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 257/265:\n",
            "Layer: 27, Position: (2938, 3290)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 258/265:\n",
            "Layer: 27, Position: (2938, 3550)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 259/265:\n",
            "Layer: 27, Position: (2938, 4577)\n",
            "Modified perplexity: 62.84\n",
            "Perplexity change: -0.40%\n",
            "--------------------------------------------------\n",
            "Candidate 260/265:\n",
            "Layer: 27, Position: (2938, 5255)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 261/265:\n",
            "Layer: 27, Position: (2938, 5365)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 262/265:\n",
            "Layer: 27, Position: (2938, 5965)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 263/265:\n",
            "Layer: 27, Position: (2938, 6023)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 264/265:\n",
            "Layer: 27, Position: (2938, 6131)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "Candidate 265/265:\n",
            "Layer: 27, Position: (2938, 6452)\n",
            "Modified perplexity: 63.09\n",
            "Perplexity change: +0.00%\n",
            "--------------------------------------------------\n",
            "\n",
            "Top 3 most influential Super weights:\n",
            "\n",
            "Candidate 1:\n",
            "Layer: 1\n",
            "Position: (2938, 7633)\n",
            "Weight value: -1.2734\n",
            "Perplexity impact: +33729.02%\n",
            "Base perplexity: 63.09\n",
            "Modified perplexity: 21344.00\n",
            "\n",
            "Candidate 2:\n",
            "Layer: 7\n",
            "Position: (1161, 546)\n",
            "Weight value: -1.1172\n",
            "Perplexity impact: +19.66%\n",
            "Base perplexity: 63.09\n",
            "Modified perplexity: 75.50\n",
            "\n",
            "Candidate 3:\n",
            "Layer: 7\n",
            "Position: (2139, 546)\n",
            "Weight value: -0.0559\n",
            "Perplexity impact: +19.17%\n",
            "Base perplexity: 63.09\n",
            "Modified perplexity: 75.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(model, tokenizer, text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_length=32,\n",
        "            num_return_sequences=1,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "atJwLkqA5Azu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_super_weight(model, tokenizer, layer_idx, row, col, text):\n",
        "    original_output = infer(model, tokenizer, text)\n",
        "    layer = model.model.layers[layer_idx]\n",
        "    original_weight = float(layer.mlp.down_proj.weight[row, col])\n",
        "    with torch.no_grad():\n",
        "        layer.mlp.down_proj.weight[row, col] = 0.0\n",
        "    sw_output = infer(model, tokenizer, text)\n",
        "    print(\"Original output:\", original_output)\n",
        "    print(\"Modified output:\", sw_output)\n",
        "    with torch.no_grad():\n",
        "        layer.mlp.down_proj.weight[row, col] = original_weight"
      ],
      "metadata": {
        "id": "bWZWO1z8E0fD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verify_super_weight(finder.model, finder.tokenizer, 1, 2938, 7633, \"日本で一番高い山は、\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpGJp3jQ5cNd",
        "outputId": "2862bacd-4bd2-4c81-b107-c303cd0fc28c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original output: 日本で一番高い山は、富士山です。\n",
            "\n",
            "富士山は標高3776mで、日本で一番高い山です。\n",
            "\n",
            "富士山は日本で一番高い\n",
            "Modified output: 日本で一番高い山は、日本で一番高い山は、日本で一番高い山は、日本で一番高い山は、日本で一番高い山は、日本\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verify_super_weight(finder.model, finder.tokenizer, 1, 1161, 546, \"日本で一番高い山は、\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbjt-Hs25oZV",
        "outputId": "c9bddafb-fac9-4e40-c2b5-a87a7ff9c9af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original output: 日本で一番高い山は、富士山です。\n",
            "\n",
            "富士山は標高3776mで、日本で一番高い山です。\n",
            "\n",
            "富士山は日本で一番高い\n",
            "Modified output: 日本で一番高い山は、富士山です。\n",
            "\n",
            "富士山は標高3776mで、日本で一番高い山です。\n",
            "\n",
            "富士山は日本で一番高い\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dtzbs96b6ULl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}